{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnSuayJCd541"
      },
      "outputs": [],
      "source": [
        "#MODEL_TYPE = \"LSTM\" # Choose between LSTM, DeepAR and MOIRAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cu7IvMymwyM",
        "outputId": "fbf6eed3-b8df-4661-a1c4-13b0c745202a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N023cFtseXHa"
      },
      "outputs": [],
      "source": [
        "# Initialize Directories and Configurations\n",
        "print(\"LSTM model type stuff\")\n",
        "\n",
        "print(\"DeepAR model type stuff\")\n",
        "# install with support for torch models\n",
        "!pip install \"gluonts[torch]\"\n",
        "# install with support for mxnet models\n",
        "!pip install \"gluonts[mxnet]\"\n",
        "\n",
        "print(\"MOIRAI model type stuff\")\n",
        "!git clone https://github.com/taschoebli/uni2ts.git\n",
        "%cd uni2ts\n",
        "!pip install -e '.[notebook]'\n",
        "#!pip install uni2ts\n",
        "!touch .env\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6YkS5WEYYYx",
        "outputId": "68a9f1d5-58f4-42ec-9043-d73a80467203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "General imports loaded\n",
            "LSTM specific imports loaded\n",
            "DeepAR specific imports loaded\n",
            "MOIRAI specific imports loaded\n"
          ]
        }
      ],
      "source": [
        "#General imports\n",
        "print(\"General imports loaded\")\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "#if MODEL_TYPE == \"LSTM\":\n",
        "print(\"LSTM specific imports loaded\")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#elif MODEL_TYPE == \"DeepAR\":\n",
        "print(\"DeepAR specific imports loaded\")\n",
        "from gluonts.torch import DeepAREstimator\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "from gluonts.dataset.split import split\n",
        "\n",
        "#elif MODEL_TYPE == \"MOIRAI\":\n",
        "print(\"MOIRAI specific imports loaded\")\n",
        "from huggingface_hub import hf_hub_download\n",
        "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
        "from uni2ts.model.moirai_moe import MoiraiMoEForecast, MoiraiMoEModule\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "from gluonts.dataset.split import split\n",
        "\n",
        "#else:\n",
        "  #print(\"Invalid model type\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "af2SkhDQZ0Bv"
      },
      "outputs": [],
      "source": [
        "# Functions, Classes and other Helpers\n",
        "\n",
        "# General ----------------------------------------------------------------------\n",
        "\n",
        "# Load data from csv\n",
        "def load_data(filepath):\n",
        "    data = pd.read_csv(filepath, index_col=0, parse_dates=True)\n",
        "    return data\n",
        "\n",
        "# Filename extractor\n",
        "def file_name_no_extension(filepath):\n",
        "  # Extract the filename without the folder path\n",
        "  filename_with_extension = os.path.basename(filepath)\n",
        "\n",
        "  # Remove the `.csv` extension\n",
        "  filename_without_extension = os.path.splitext(filename_with_extension)[0]\n",
        "\n",
        "  return filename_without_extension\n",
        "\n",
        "\n",
        "# Day extractor\n",
        "def get_values_by_day(df_internal, offset=0):\n",
        "  # Ensure index is datetime\n",
        "  if not isinstance(df_internal.index, pd.DatetimeIndex):\n",
        "      df_internal.index = pd.to_datetime(df_internal.index)\n",
        "\n",
        "  # Apply offset by removing the last 'offset' rows\n",
        "  if offset > 0:\n",
        "      df_internal = df_internal.iloc[:-offset]\n",
        "\n",
        "  # Filter timestamps to only include those at exactly 08:00\n",
        "  df_filtered = df_internal[df_internal.index.hour == 8]\n",
        "\n",
        "  # Group by date and store in a dictionary\n",
        "  #result = {}\n",
        "  #for date, group in df_filtered.groupby(df_filtered.index.date):\n",
        "      #result[str(date)] = group.index.tolist()\n",
        "  # Extract timestamps as strings instead of lists\n",
        "  result = {group.index[0].strftime('%Y-%m-%d %H:%M:%S') for date, group in df_filtered.groupby(df_filtered.index.date)}\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "# Calculate SMAPE metric\n",
        "def calc_smape(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculate the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
        "  y_true: array-like, actual values\n",
        "  y_pred: array-like, predicted values\n",
        "  \"\"\"\n",
        "  epsilon = 1e-10  # Small constant to avoid division by zero\n",
        "  denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "  smape_values = np.abs(y_true - y_pred) / (denominator + epsilon)\n",
        "  smape_values = np.nan_to_num(smape_values, nan=0.0, posinf=0.0, neginf=0.0)  # Handle division by zero\n",
        "\n",
        "  return np.mean(smape_values) * 100  # Convert to percentage\n",
        "\n",
        "def optimize_memory():\n",
        "  # Memory optimization\n",
        "  # Set CUDA memory management configuration to avoid fragmentation\n",
        "  # https://pytorch.org/docs/stable/notes/cuda.html#using-custom-memory-allocators-for-cuda\n",
        "  os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "  # Check if CUDA is available\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device: {device}\")\n",
        "  torch.cuda.empty_cache()\n",
        "  os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]\n",
        "\n",
        "\n",
        "# LSTM specific ----------------------------------------------------------------\n",
        "\n",
        "# Create sequences for time-series prediction\n",
        "def create_sequences(features, target, context_length, prediction_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(features) - context_length - prediction_length + 1):\n",
        "        X_seq.append(features[i:i+context_length])  # Past `context_length` values\n",
        "        y_seq.append(target[i+context_length:i+context_length+prediction_length])  # Next `prediction_length` values\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# Define the LSTM Model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        out = self.fc(hidden[-1])  # Use the last hidden state\n",
        "        return out\n",
        "\n",
        "def train_LSTM_model(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}')\n",
        "    return epoch_loss/len(train_loader)\n",
        "\n",
        "def evaluate_LSTM_model(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            outputs = model(X_batch)\n",
        "            predictions.extend(outputs.tolist())\n",
        "            actuals.extend(y_batch.tolist())\n",
        "    # Feature added here!!!\n",
        "    # Truncate negative predictions to 0\n",
        "    predictions = np.maximum(predictions, 0)\n",
        "    return np.array(predictions), np.array(actuals)\n",
        "\n",
        "def get_index_and_timestamp_for_validation(hour, original_df, train_size):\n",
        "    \"\"\"\n",
        "    Finds the first available testdata tensor index that matches the given hour.\n",
        "\n",
        "    Parameters:\n",
        "    - hour (int): The desired hour (0-23).\n",
        "    - original_df (pd.DataFrame): The original dataset with a datetime index.\n",
        "    - train_size (int): The number of samples in the training dataset + Context Length.\n",
        "\n",
        "    Returns:\n",
        "    - test_index (int): The index relative to testdata tensor.\n",
        "    - timestamp (str): The corresponding datetime string.\n",
        "    \"\"\"\n",
        "    # Ensure datetime format\n",
        "    original_df.index = pd.to_datetime(original_df.index)\n",
        "\n",
        "    # Extract test dataset portion\n",
        "    test_df = original_df.iloc[train_size:]  # This contains only the test set\n",
        "\n",
        "    # Find the first row where the hour matches\n",
        "    for i, timestamp in enumerate(test_df.index):\n",
        "        if timestamp.hour == hour:\n",
        "            test_index = i  # Relative index in testdata tensor\n",
        "            return test_index, timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    raise ValueError(f\"No test data found at hour {hour}:00.\")\n",
        "\n",
        "\n",
        "def truncate_tensor_with_interval(tensor, start_index, offset=1):\n",
        "    \"\"\"\n",
        "    Truncates the given tensor along the first dimension, starting at start_index,\n",
        "    and selects every `offset`-th row.\n",
        "\n",
        "    Parameters:\n",
        "    - tensor (torch.Tensor): The input tensor (shape: [X, Y]).\n",
        "    - start_index (int): The base index from which truncation starts.\n",
        "    - offset (int): Step interval to select elements (e.g., every 4th, 12th, etc.).\n",
        "\n",
        "    Returns:\n",
        "    - truncated_tensor (torch.Tensor): The truncated tensor with selected intervals.\n",
        "    \"\"\"\n",
        "    if start_index >= tensor.shape[0]:\n",
        "        raise ValueError(\"Start index exceeds tensor dimensions.\")\n",
        "\n",
        "    # Make sure that below 24 hours, offset is set to one day!\n",
        "    if offset < 24:\n",
        "      offset = 24\n",
        "\n",
        "    return tensor[start_index::offset]  # Truncate and select every `offset` step\n",
        "\n",
        "def data_validation_LSTM(df, actuals, X_train, CONTEXT_LENGTH, PREDICTION_LENGTH, hour=8):\n",
        "    \"\"\"\n",
        "    Validates the actual LSTM predictions against the true values in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The original dataset with a datetime index.\n",
        "    - actuals (torch.Tensor): The model's predicted values (shape: [X, Y]).\n",
        "    - X_train (numpy array or tensor): The training dataset.\n",
        "    - CONTEXT_LENGTH (int): The number of past timesteps used for forecasting.\n",
        "    - PREDICTION_LENGTH (int): The number of future timesteps predicted.\n",
        "    - hour (int): The desired hour (default: 8 AM).\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Get the test index and timestamp\n",
        "    INDEX, timestamp = get_index_and_timestamp_for_validation(hour, df, train_size=len(X_train) + CONTEXT_LENGTH)\n",
        "\n",
        "    # Step 2: Extract predictions using the computed index\n",
        "    actuals_daily = truncate_tensor_with_interval(actuals, INDEX, offset=PREDICTION_LENGTH)\n",
        "\n",
        "    # Step 3: Retrieve true values from `df['OT']`\n",
        "    start_index = len(X_train) + CONTEXT_LENGTH + INDEX\n",
        "    true_values = df['OT'].iloc[start_index:start_index + PREDICTION_LENGTH].values  # Convert to NumPy array\n",
        "\n",
        "    # Step 4: Format values for comparison\n",
        "    formatted_actuals = np.round(actuals_daily[0], 1)  # Convert tensor to NumPy & round\n",
        "    formatted_true_values = np.round(true_values, 1)  # Round true values for comparison\n",
        "\n",
        "    # Step 5: Print Debugging Information\n",
        "    print(\"üîç Validation at timestamp:\", timestamp)\n",
        "    print(\"Predicted Values (Rounded):\")\n",
        "    print(f\"{formatted_actuals}\")\n",
        "    print(\"True Values (Rounded):\")\n",
        "    print(f\"{formatted_true_values}\")\n",
        "\n",
        "    # Step 6: Perform Validation Check\n",
        "    validation_passed = np.array_equal(formatted_actuals, formatted_true_values)\n",
        "\n",
        "    print(\"\\n‚úÖ Validation Passed\" if validation_passed else \"\\n‚ùå Validation Failed\")\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "def days_between_dates(date_str1: str, date_str2: str, date_format: str = \"%Y-%m-%d %H:%M:%S\") -> int:\n",
        "    \"\"\"\n",
        "    Returns the number of days between two datetime strings.\n",
        "\n",
        "    :param date_str1: First date string\n",
        "    :param date_str2: Second date string\n",
        "    :param date_format: Format of the date strings (default: \"%Y-%m-%d %H:%M:%S\")\n",
        "    :return: Number of days between the two dates (absolute value)\n",
        "    \"\"\"\n",
        "    date1 = datetime.strptime(date_str1, date_format)\n",
        "    date2 = datetime.strptime(date_str2, date_format)\n",
        "    return abs((date2 - date1).days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b_AgDYt-8_z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7oYYV-DYpgB",
        "outputId": "7ff6a1f2-9749-45f8-a7d9-abed6c4d17bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM model definitions and constants loaded\n",
            "DeepAR model type stuff\n",
            "MOIRAI model type stuff\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Definitions and Constants\n",
        "FILEPATH = '/content/sample_data/160701_180626_ETTh1.csv'\n",
        "PREDICTION_LENGTH_LIST = [4, 12, 24, 48, 96, 336] # Use the past 4, 12, 24, 48, 96, 336 time steps for prediction (4 hours to 14 days)\n",
        "CONTEXT_LENGTH_FOLD_LIST = [1, 2, 4, 8] # Use 1, 2, 4 and 8 fold PREDICTION_LENGTH\n",
        "BEGINNING_TIMESTAMP = \"2017-07-04 08:00:00\"\n",
        "START_HOUR = 8 # Use to start plots at this hour\n",
        "TRAIN_DATA_LAST_INDEX = 8786 # Corresponds to '2024-04-01 00:00:00', used for LSTM and DeepAR in 230401_250108_PT1H_Solcast_reduced_features.csv\n",
        "\n",
        "print(\"LSTM model definitions and constants loaded\")\n",
        "LSTM_HIDDEN_SIZE = 64  # Number of hidden units -> # of neurons in the LSTM's hidden layer\n",
        "LSTM_BATCH_SIZE = 64  # Batch size -> # of samples processed in parallel\n",
        "LSTM_NUM_LAYERS = 2  # Number of LSTM layers -> # of stacked LSTM layers\n",
        "LSTM_LR = 1e-3\n",
        "LSTM_NUM_EPOCHS = 25\n",
        "\n",
        "print(\"DeepAR model type stuff\")\n",
        "DeepAR_HIDDEN_SIZE = 64 # Number of RNN cells for each layer (default: 40)\n",
        "DeepAR_NUM_LAYERS = 2 # Number of RNN layers (default: 2)\n",
        "DeepAR_LR = 1e-3\n",
        "DeepAR_NUM_EPOCHS = 25\n",
        "\n",
        "print(\"MOIRAI model type stuff\")\n",
        "MOIRAI_PATCH_SIZE = 32 # patch size, Number of samples for each layer or sequence, 32 or 64 recommended for hourly\n",
        "MOIRAI_BATCH_SIZE = 16 # batch size, samples processed in parallel\n",
        "MOIRAI_MODEL = \"moirai-1.1-R\"  # model name: choose from {'moirai-1.1-R', 'moirai-moe-1.0-R'}\n",
        "MOIRAI_SIZE = \"base\"  # model size: choose from {'small', 'base', 'large'}\n",
        "MOIRAI_MODEL_STR = f\"Salesforce/{MOIRAI_MODEL}-{MOIRAI_SIZE}\"\n",
        "MOIRAI_MODEL_PATH_SAFE = MOIRAI_MODEL_STR.replace(\"Salesforce/\", \"\").replace(\"/\", \"-\").replace(\".\", \"-\")\n",
        "\n",
        "optimize_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eOuzkZPrXDYf"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load data from csv\n",
        "df = load_data(FILEPATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "AwyPxPrUcrFi",
        "outputId": "1249057c-ae70-426d-e61e-762e672efa5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM feature scaling\n",
            "DeepAR OR MOIRAI feature scaling\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# For Unisolar\\ndataset = PandasDataset(df, target=\"dc_power\",\\n                      past_feat_dynamic_real=[\\'dc_power\\', \\'CloudOpacity\\', \\'Ghi\\', \\'ApparentTemperature\\', \\'AirTemperature\\', \\'DewPointTemperature\\', \\'RelativeHumidity\\', \\'WindSpeed\\', \\'WindDirection\\'],\\n                      feat_dynamic_real=[\\'CloudOpacity\\', \\'Ghi\\', \\'ApparentTemperature\\', \\'AirTemperature\\', \\'DewPointTemperature\\', \\'RelativeHumidity\\', \\'WindSpeed\\', \\'WindDirection\\'])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "## Step 2: Feature Scaling\n",
        "print(\"LSTM feature scaling\")\n",
        "# Separate features and target\n",
        "LSTM_target_column = 'OT'\n",
        "\n",
        "# For Solcast\n",
        "LSTM_features = [\n",
        "    'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL'\n",
        "]\n",
        "\"\"\"\n",
        "# For Unisolar\n",
        "LSTM_features = [\n",
        "    'CloudOpacity', 'Ghi', 'ApparentTemperature', 'AirTemperature', 'DewPointTemperature', 'RelativeHumidity', 'WindSpeed', 'WindDirection'\n",
        "]\n",
        "\"\"\"\n",
        "X = df[LSTM_features]\n",
        "y = df[LSTM_target_column]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "#scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert target to a numpy array\n",
        "y = y.to_numpy()\n",
        "\n",
        "print(\"DeepAR OR MOIRAI feature scaling\")\n",
        "# https://ts.gluon.ai/dev/api/gluonts/gluonts.dataset.pandas.html\n",
        "# Convert into GluonTS dataset with features\n",
        "\n",
        "# For Solcast\n",
        "# For ETTH1\n",
        "dataset = PandasDataset(df, target=\"OT\",\n",
        "                        past_feat_dynamic_real=['OT', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL'],\n",
        "                        feat_dynamic_real=['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL'])\n",
        "\"\"\"\n",
        "# For Unisolar\n",
        "dataset = PandasDataset(df, target=\"dc_power\",\n",
        "                      past_feat_dynamic_real=['dc_power', 'CloudOpacity', 'Ghi', 'ApparentTemperature', 'AirTemperature', 'DewPointTemperature', 'RelativeHumidity', 'WindSpeed', 'WindDirection'],\n",
        "                      feat_dynamic_real=['CloudOpacity', 'Ghi', 'ApparentTemperature', 'AirTemperature', 'DewPointTemperature', 'RelativeHumidity', 'WindSpeed', 'WindDirection'])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cc0d86a8aca74b6aa143ef4f08f6cdc2",
            "f03cff7868524d5383021b2031243c52",
            "a81dc12a61994d81b4e0f49b2ac7a425",
            "f21a7b516e1e43d79f9d9bf0014cd1aa",
            "32a5388b987a4713b3dc6ee4cc91b9ad",
            "7b32e5259b2e43b2afdce4f57faeffdd",
            "330de12a817b4bacb57b751c9cbc7b7b",
            "831885f9a5614c1e83b001bd194b2b68",
            "5b822939194948edb9e567b95de10955",
            "0c148f95e16848628873e503d4338811",
            "e61e0b91577e46a8921e51d3d0ecb192",
            "6a96f2301dcc4666b18271114cc34efe",
            "9ac267a0bdc44b31b787a7e1ac47ed02",
            "94aa5ce6d2ba43f59495e45383b027c6",
            "eddfc6d5b57544bbb7b5a4c9a1b56858",
            "241485d020c54097a4de2ec33fd1e34e",
            "10918e541f4b4a68833c1bda7cb9166e",
            "fa830d1c600043f9a2178f6028c4d1b8",
            "9307391a3e19437c82876920377e7021",
            "548b21f922d34afbb1ee3793cc7774b1",
            "dc7804ce417d4e33952a038c46350ce7",
            "15b970e6b4fe4004908f4db9c2566ca8",
            "43793583ff414f9884263bb7a218c475",
            "41669828f3334e26975cb35321d01f51",
            "c4db20f3cffa4dfca8c5d8eb36999d41",
            "794a35f1460d4d50b2627d164e192fd1",
            "1d9778648d644caaa3273745ad15b521",
            "825d7ba13c544260a9c0e25ad4cb23e7",
            "8abf5d19f02941c2a82025193f91b13b",
            "aee95827ec844b5da11c189ad203dc70",
            "5ff17b2403a84ebcb2548bc108db7a53",
            "e92519c046224b51bb8d4668b9e25d8d",
            "41c102a4865547d5abcd39b5a84643b4",
            "e0904154404e453fa1ec5dd3d74e949d",
            "a4c79a5d3c3d4b9487e1b05c0ac6a7a0",
            "dc2bc0558b2c405ab2769d1ef28baebf",
            "ac6fccc2caf8484c8c48ede352823013",
            "2ec9b5634b484e97bbe43ef208973be1",
            "5d47ef833ad74215b6e896833059fab1",
            "366d129e2c9e4152881c89cd19dd992e",
            "cb6f6ce7f47f455b85570abaaae0d82c",
            "dce88247da8d45ff9afd233bf9cbf0f5",
            "3a39dae672594e8fad0190e527b04dc6",
            "905e293786f140d6b1afd6994b9f9dde",
            "053cc02e3de3434790d020ec024a912f",
            "5201de53a1c944c6862d7b2dc3027584",
            "6b9b5e4699784f7b8a0833c8677e1a2b",
            "cd5c2600f4464ddcb4675cf35abf56e8",
            "5e1936fcb4204b5cac8f67d22622ada6",
            "8c36c0a577424904b607192b7d76dfa2",
            "66a3b53135db4db2afdd0b36dae51541",
            "89e00378bcd64d6392893929501817d8",
            "7bd617cae5904119b783c462fb7aa3be",
            "8fdaad6c5c3f4600a3b70e8695149746",
            "c038d45d53be47bba66e41caa1c83416"
          ]
        },
        "id": "HD2g7m_5hOaq",
        "outputId": "99829236-87a4-4388-80c2-3be51b396fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM model - Main block\n",
            "Epoch 1/25, Loss: 274.0655\n",
            "Epoch 2/25, Loss: 115.0819\n",
            "Epoch 3/25, Loss: 94.0128\n",
            "Epoch 4/25, Loss: 83.7928\n",
            "Epoch 5/25, Loss: 84.9034\n",
            "Epoch 6/25, Loss: 72.4860\n",
            "Epoch 7/25, Loss: 67.9662\n",
            "Epoch 8/25, Loss: 64.2676\n",
            "Epoch 9/25, Loss: 63.5851\n",
            "Epoch 10/25, Loss: 61.9437\n",
            "Epoch 11/25, Loss: 60.3132\n",
            "Epoch 12/25, Loss: 59.2271\n",
            "Epoch 13/25, Loss: 58.2985\n",
            "Epoch 14/25, Loss: 57.3936\n",
            "Epoch 15/25, Loss: 56.7419\n",
            "Epoch 16/25, Loss: 55.4439\n",
            "Epoch 17/25, Loss: 55.3226\n",
            "Epoch 18/25, Loss: 53.7765\n",
            "Epoch 19/25, Loss: 55.7500\n",
            "Epoch 20/25, Loss: 52.5371\n",
            "Epoch 21/25, Loss: 51.6666\n",
            "Epoch 22/25, Loss: 50.4193\n",
            "Epoch 23/25, Loss: 51.8694\n",
            "Epoch 24/25, Loss: 51.9692\n",
            "Epoch 25/25, Loss: 48.8330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Validation at timestamp: 2017-07-02 08:00:00\n",
            "Predicted Values (Rounded):\n",
            "[12.9 10.5 12.3 16.1]\n",
            "True Values (Rounded):\n",
            "[12.9 10.5 12.3 16.1]\n",
            "\n",
            "‚úÖ Validation Passed\n",
            "PL=4, CL=4, Model=LSTM\n",
            "\n",
            "DeepAR model type stuff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: \n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                       | Out sizes  \n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 64.2 K | train | [[1, 1], [1, 1], [1, 724, 11], [1, 724], [1, 724], [1, 4, 11]] | [1, 100, 4]\n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "64.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "64.2 K    Total params\n",
            "0.257     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                       | Out sizes  \n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 64.2 K | train | [[1, 1], [1, 1], [1, 724, 11], [1, 724], [1, 724], [1, 4, 11]] | [1, 100, 4]\n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "64.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "64.2 K    Total params\n",
            "0.257     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc0d86a8aca74b6aa143ef4f08f6cdc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Epoch 0, global step 50: 'train_loss' reached 2.97250 (best 2.97250), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 2.97250 (best 2.97250), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.06666 (best 2.06666), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.06666 (best 2.06666), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 1.91802 (best 1.91802), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 1.91802 (best 1.91802), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 1.78732 (best 1.78732), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 1.78732 (best 1.78732), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.66634 (best 1.66634), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.66634 (best 1.66634), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.59010 (best 1.59010), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.59010 (best 1.59010), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.58930 (best 1.58930), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.58930 (best 1.58930), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.55973 (best 1.55973), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.55973 (best 1.55973), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.54393 (best 1.54393), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.54393 (best 1.54393), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.53171 (best 1.53171), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.53171 (best 1.53171), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.50998 (best 1.50998), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.50998 (best 1.50998), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.48710 (best 1.48710), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.48710 (best 1.48710), saving model to '/content/lightning_logs/version_0/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=25` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=25` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PL=4, CL=4, Model=DeepAR\n",
            "MOIRAI model type stuff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/683 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a96f2301dcc4666b18271114cc34efe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/365M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43793583ff414f9884263bb7a218c475"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PL=4, CL=4, Model=moirai-1-1-R-base\n",
            "\n",
            "LSTM model - Main block\n",
            "Epoch 1/25, Loss: 273.3544\n",
            "Epoch 2/25, Loss: 124.0941\n",
            "Epoch 3/25, Loss: 95.7459\n",
            "Epoch 4/25, Loss: 88.0527\n",
            "Epoch 5/25, Loss: 78.4717\n",
            "Epoch 6/25, Loss: 68.0938\n",
            "Epoch 7/25, Loss: 62.6342\n",
            "Epoch 8/25, Loss: 61.2328\n",
            "Epoch 9/25, Loss: 57.2118\n",
            "Epoch 10/25, Loss: 56.6857\n",
            "Epoch 11/25, Loss: 55.2056\n",
            "Epoch 12/25, Loss: 54.7902\n",
            "Epoch 13/25, Loss: 53.9482\n",
            "Epoch 14/25, Loss: 53.7157\n",
            "Epoch 15/25, Loss: 53.2199\n",
            "Epoch 16/25, Loss: 52.9322\n",
            "Epoch 17/25, Loss: 52.3241\n",
            "Epoch 18/25, Loss: 52.5463\n",
            "Epoch 19/25, Loss: 51.7252\n",
            "Epoch 20/25, Loss: 51.5626\n",
            "Epoch 21/25, Loss: 50.9577\n",
            "Epoch 22/25, Loss: 50.3078\n",
            "Epoch 23/25, Loss: 51.2733\n",
            "Epoch 24/25, Loss: 49.4584\n",
            "Epoch 25/25, Loss: 48.9229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: \n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                       | Out sizes  \n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 64.2 K | train | [[1, 1], [1, 1], [1, 728, 11], [1, 728], [1, 728], [1, 4, 11]] | [1, 100, 4]\n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "64.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "64.2 K    Total params\n",
            "0.257     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                       | Out sizes  \n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 64.2 K | train | [[1, 1], [1, 1], [1, 728, 11], [1, 728], [1, 728], [1, 4, 11]] | [1, 100, 4]\n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "64.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "64.2 K    Total params\n",
            "0.257     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Validation at timestamp: 2017-07-03 08:00:00\n",
            "Predicted Values (Rounded):\n",
            "[19.6 19.1 19.2 19.3]\n",
            "True Values (Rounded):\n",
            "[19.6 19.1 19.2 19.3]\n",
            "\n",
            "‚úÖ Validation Passed\n",
            "PL=4, CL=8, Model=LSTM\n",
            "\n",
            "DeepAR model type stuff\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0904154404e453fa1ec5dd3d74e949d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Epoch 0, global step 50: 'train_loss' reached 2.98208 (best 2.98208), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 2.98208 (best 2.98208), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.12014 (best 2.12014), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.12014 (best 2.12014), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 1.96847 (best 1.96847), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 1.96847 (best 1.96847), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 1.87208 (best 1.87208), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 1.87208 (best 1.87208), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.86367 (best 1.86367), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.86367 (best 1.86367), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.76971 (best 1.76971), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.76971 (best 1.76971), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.72944 (best 1.72944), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.72944 (best 1.72944), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.72884 (best 1.72884), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.72884 (best 1.72884), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.66102 (best 1.66102), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.66102 (best 1.66102), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.64552 (best 1.64552), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.64552 (best 1.64552), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.63693 (best 1.63693), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.63693 (best 1.63693), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.62445 (best 1.62445), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.62445 (best 1.62445), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.60895 (best 1.60895), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.60895 (best 1.60895), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.58078 (best 1.58078), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.58078 (best 1.58078), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.53648 (best 1.53648), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.53648 (best 1.53648), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.53347 (best 1.53347), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.53347 (best 1.53347), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.48393 (best 1.48393), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.48393 (best 1.48393), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.45049 (best 1.45049), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.45049 (best 1.45049), saving model to '/content/lightning_logs/version_1/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=25` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=25` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PL=4, CL=8, Model=DeepAR\n",
            "MOIRAI model type stuff\n",
            "PL=4, CL=8, Model=moirai-1-1-R-base\n",
            "\n",
            "LSTM model - Main block\n",
            "Epoch 1/25, Loss: 273.4504\n",
            "Epoch 2/25, Loss: 129.2210\n",
            "Epoch 3/25, Loss: 99.1942\n",
            "Epoch 4/25, Loss: 86.2689\n",
            "Epoch 5/25, Loss: 76.1761\n",
            "Epoch 6/25, Loss: 65.0866\n",
            "Epoch 7/25, Loss: 58.9231\n",
            "Epoch 8/25, Loss: 60.2867\n",
            "Epoch 9/25, Loss: 56.5920\n",
            "Epoch 10/25, Loss: 55.5931\n",
            "Epoch 11/25, Loss: 54.1076\n",
            "Epoch 12/25, Loss: 54.4261\n",
            "Epoch 13/25, Loss: 51.8541\n",
            "Epoch 14/25, Loss: 54.0352\n",
            "Epoch 15/25, Loss: 50.1283\n",
            "Epoch 16/25, Loss: 52.9750\n",
            "Epoch 17/25, Loss: 49.2777\n",
            "Epoch 18/25, Loss: 51.4091\n",
            "Epoch 19/25, Loss: 49.8153\n",
            "Epoch 20/25, Loss: 50.3675\n",
            "Epoch 21/25, Loss: 48.1330\n",
            "Epoch 22/25, Loss: 47.5978\n",
            "Epoch 23/25, Loss: 46.9970\n",
            "Epoch 24/25, Loss: 45.9425\n",
            "Epoch 25/25, Loss: 44.9328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: \n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                       | Out sizes  \n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 64.2 K | train | [[1, 1], [1, 1], [1, 736, 11], [1, 736], [1, 736], [1, 4, 11]] | [1, 100, 4]\n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "64.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "64.2 K    Total params\n",
            "0.257     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                       | Out sizes  \n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 64.2 K | train | [[1, 1], [1, 1], [1, 736, 11], [1, 736], [1, 736], [1, 4, 11]] | [1, 100, 4]\n",
            "-----------------------------------------------------------------------------------------------------------------------------\n",
            "64.2 K    Trainable params\n",
            "0         Non-trainable params\n",
            "64.2 K    Total params\n",
            "0.257     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Validation at timestamp: 2017-07-03 08:00:00\n",
            "Predicted Values (Rounded):\n",
            "[19.6 19.1 19.2 19.3]\n",
            "True Values (Rounded):\n",
            "[19.6 19.1 19.2 19.3]\n",
            "\n",
            "‚úÖ Validation Passed\n",
            "PL=4, CL=16, Model=LSTM\n",
            "\n",
            "DeepAR model type stuff\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "053cc02e3de3434790d020ec024a912f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Epoch 0, global step 50: 'train_loss' reached 2.99454 (best 2.99454), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 2.99454 (best 2.99454), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.15993 (best 2.15993), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.15993 (best 2.15993), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.05567 (best 2.05567), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.05567 (best 2.05567), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 1.94436 (best 1.94436), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 1.94436 (best 1.94436), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.87452 (best 1.87452), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.87452 (best 1.87452), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.83115 (best 1.83115), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.83115 (best 1.83115), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.79040 (best 1.79040), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.79040 (best 1.79040), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.74105 (best 1.74105), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.74105 (best 1.74105), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.70533 (best 1.70533), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.70533 (best 1.70533), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.66672 (best 1.66672), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.66672 (best 1.66672), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.64480 (best 1.64480), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.64480 (best 1.64480), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.55970 (best 1.55970), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.55970 (best 1.55970), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.53124 (best 1.53124), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.53124 (best 1.53124), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.48086 (best 1.48086), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.48086 (best 1.48086), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.45588 (best 1.45588), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.45588 (best 1.45588), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.43685 (best 1.43685), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.43685 (best 1.43685), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.41322 (best 1.41322), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.41322 (best 1.41322), saving model to '/content/lightning_logs/version_2/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=25` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=25` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PL=4, CL=16, Model=DeepAR\n",
            "MOIRAI model type stuff\n",
            "PL=4, CL=16, Model=moirai-1-1-R-base\n",
            "\n",
            "LSTM model - Main block\n",
            "Epoch 1/25, Loss: 273.0662\n"
          ]
        }
      ],
      "source": [
        "# Main block - run for several iterations\n",
        "\n",
        "for prediction_length in sorted(PREDICTION_LENGTH_LIST):\n",
        "  for context_length_fold in sorted(CONTEXT_LENGTH_FOLD_LIST):\n",
        "    PREDICTION_LENGTH = prediction_length\n",
        "    CONTEXT_LENGTH = context_length_fold * PREDICTION_LENGTH\n",
        "\n",
        "    print(\"LSTM model - Main block\")\n",
        "    # Step 3: Create sequences\n",
        "    X_seq, y_seq = create_sequences(X_scaled, y, CONTEXT_LENGTH, PREDICTION_LENGTH)\n",
        "\n",
        "    # Step 4: Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, train_size=TRAIN_DATA_LAST_INDEX, random_state=None, shuffle=False)\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "    # Step 5: Create DataLoader for batch processing\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    test_dataset = TensorDataset(X_test, y_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=LSTM_BATCH_SIZE, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=LSTM_BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Step 6: Create the model\n",
        "    input_size = X_train.shape[2]  # Number of features -> 7 eg. 'air_temp', 'albedo', etc.\n",
        "    model = LSTMModel(input_size, LSTM_HIDDEN_SIZE, LSTM_NUM_LAYERS, output_size=PREDICTION_LENGTH)\n",
        "\n",
        "    # Step 7: Define the loss function and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), LSTM_LR)\n",
        "\n",
        "    # Step 8: Train the model\n",
        "    LOSS = train_LSTM_model(model, train_loader, criterion, optimizer, LSTM_NUM_EPOCHS)\n",
        "\n",
        "    # Step 9: Evaluate the model\n",
        "    LSTM_predictions, LSTM_actuals = evaluate_LSTM_model(model, test_loader)\n",
        "    data_validation_LSTM(df, LSTM_actuals, X_train, CONTEXT_LENGTH, PREDICTION_LENGTH, hour=START_HOUR)\n",
        "    INDEX, TIMESTAMP = get_index_and_timestamp_for_validation(START_HOUR, df, train_size=len(X_train) + CONTEXT_LENGTH)\n",
        "    #TIMESTAMP_DATE = TIMESTAMP.split(\" \")[0]\n",
        "    #LSTM_actuals_daily = truncate_tensor_with_interval(LSTM_actuals, INDEX, offset=PREDICTION_LENGTH)\n",
        "    #LSTM_predictions_daily = truncate_tensor_with_interval(LSTM_predictions, INDEX, offset=PREDICTION_LENGTH)\n",
        "\n",
        "    # To allign with MOIRAI and DeepAR\n",
        "    LSTM_PREDICTIONS_INDEX_SHIFTED = days_between_dates(TIMESTAMP, BEGINNING_TIMESTAMP) * 24\n",
        "\n",
        "    # Step 10: Calc metrics\n",
        "\n",
        "    LSTM_rmse = np.sqrt(np.mean((LSTM_predictions - LSTM_actuals)**2))\n",
        "    LSTM_mae = mean_absolute_error(LSTM_actuals, LSTM_predictions)\n",
        "    LSTM_r2 = r2_score(LSTM_actuals, LSTM_predictions)\n",
        "    LSTM_smape = calc_smape(LSTM_actuals, LSTM_predictions)\n",
        "    print(f\"PL={PREDICTION_LENGTH}, CL={CONTEXT_LENGTH}, Model=LSTM\")\n",
        "    #print(f\"Length of: RMSE={len(LSTM_rmse_list)}, MAE={len(LSTM_mae_list)}, SMAPE={len(LSTM_smape_list)}, R2={len(LSTM_r2_list)}\")\n",
        "    #print(f\"Mean of: RMSE={np.mean(LSTM_rmse_list):.4f}, MAE={np.mean(LSTM_mae_list):.4f}, SMAPE={np.mean(LSTM_smape_list):.2f}%, R^2={np.mean(LSTM_r2_list):.4f}\")\n",
        "    #LSTM_RMSE_MED = np.median(LSTM_rmse_list)\n",
        "    #LSTM_MAE_MED = np.median(LSTM_mae_list)\n",
        "    #LSTM_SMAPE_MED = np.median(LSTM_smape_list)\n",
        "    #LSTM_R2_MED = np.median(LSTM_r2_list)\n",
        "    #print(f\"Median of: RMSE={LSTM_RMSE_MED:.4f}, MAE={LSTM_MAE_MED:.4f}, SMAPE={LSTM_SMAPE_MED:.2f}%, R^2={LSTM_R2_MED:.4f}\")\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "    print(\"DeepAR model type stuff\")\n",
        "\n",
        "    # Step 3: Split data into training and testing sets\n",
        "    TESTDATA_LENGTH = len(df) - TRAIN_DATA_LAST_INDEX\n",
        "\n",
        "    # Step 4: Create test sequences for time-series prediction\n",
        "    training_data, test_gen = split(dataset, date=pd.Period(BEGINNING_TIMESTAMP, freq=\"h\"))\n",
        "    test_data = test_gen.generate_instances(prediction_length=PREDICTION_LENGTH, windows=1)\n",
        "\n",
        "    # Step5: Define and Train the model\n",
        "    model = DeepAREstimator(\n",
        "        prediction_length=PREDICTION_LENGTH, context_length=CONTEXT_LENGTH, freq=dataset.freq,\n",
        "        trainer_kwargs={\"max_epochs\": DeepAR_NUM_EPOCHS},\n",
        "        num_feat_dynamic_real=dataset.num_feat_dynamic_real,\n",
        "        num_layers=DeepAR_NUM_LAYERS,\n",
        "        hidden_size=DeepAR_HIDDEN_SIZE,\n",
        "        lr=DeepAR_LR,\n",
        "    ).train(training_data)\n",
        "\n",
        "    # Step 6: Get probabilistic predictions\n",
        "    forecasts = list(model.predict(test_data.input))\n",
        "\n",
        "    # Step 7: Get point predictions\n",
        "    # Get predictions from forecasts\n",
        "    predictions = forecasts[0].mean_ts\n",
        "\n",
        "    # Feature added here!!!\n",
        "    # Truncate negative predictions to 0\n",
        "    predictions = np.maximum(predictions, 0)\n",
        "\n",
        "    # Get actuals for metric calculations later\n",
        "    actuals = df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH][\"OT\"]\n",
        "\n",
        "    # Change type\n",
        "    DeepAR_predictions = predictions.to_numpy()\n",
        "    DeepAR_actuals = actuals.to_numpy()\n",
        "\n",
        "    # Step 8: Do evaluations\n",
        "    DeepAR_rmse = np.sqrt(np.mean((DeepAR_predictions - DeepAR_actuals)**2))\n",
        "    DeepAR_mae = mean_absolute_error(DeepAR_actuals, DeepAR_predictions)\n",
        "    DeepAR_r2 = r2_score(DeepAR_actuals, DeepAR_predictions)\n",
        "    DeepAR_smape = calc_smape(DeepAR_actuals, DeepAR_predictions)\n",
        "\n",
        "    print(f\"PL={PREDICTION_LENGTH}, CL={CONTEXT_LENGTH}, Model=DeepAR\")\n",
        "    #print(f\"Length of: RMSE={len(DeepAR_rmse_list)}, MAE={len(DeepAR_mae_list)}, SMAPE={len(DeepAR_smape_list)}, R2={len(DeepAR_r2_list)}\")\n",
        "    #print(f\"Mean of: RMSE={np.mean(DeepAR_rmse_list):.4f}, MAE={np.mean(DeepAR_mae_list):.4f}, SMAPE={np.mean(DeepAR_smape_list):.2f}%, R^2={np.mean(DeepAR_r2_list):.4f}\")\n",
        "    #DeepAR_RMSE_MED = np.median(DeepAR_rmse_list)\n",
        "    #DeepAR_MAE_MED = np.median(DeepAR_mae_list)\n",
        "    #DeepAR_SMAPE_MED = np.median(DeepAR_smape_list)\n",
        "    #DeepAR_R2_MED = np.median(DeepAR_r2_list)\n",
        "    #print(f\"Median of: RMSE={DeepAR_RMSE_MED:.4f}, MAE={DeepAR_MAE_MED:.4f}, SMAPE={DeepAR_SMAPE_MED:.2f}%, R^2={DeepAR_R2_MED:.4f}\")\n",
        "    #print(\"\")\n",
        "\n",
        "    # Prepare for Plot\n",
        "    # Get prediction intervals\n",
        "    DeepAR_lower_50 = forecasts[0].quantile(0.25)  # 25th percentile (lower bound)\n",
        "    DeepAR_upper_50 = forecasts[0].quantile(0.75)  # 75th percentile (upper bound)\n",
        "    DeepAR_lower_90 = forecasts[0].quantile(0.05)  # 5th percentile (lower bound)\n",
        "    DeepAR_upper_90 = forecasts[0].quantile(0.95)  # 95th percentile (upper bound)\n",
        "\n",
        "\n",
        "    print(\"MOIRAI model type stuff\")\n",
        "\n",
        "    # Step 2.1: Prepare pre-trained model by downloading model weights from huggingface hub\n",
        "    if \"moirai-moe\" in MOIRAI_MODEL_STR:\n",
        "      model = MoiraiMoEForecast(\n",
        "        module=MoiraiMoEModule.from_pretrained(MOIRAI_MODEL_STR),\n",
        "        prediction_length=PREDICTION_LENGTH,\n",
        "        context_length=CONTEXT_LENGTH,\n",
        "        patch_size=MOIRAI_PATCH_SIZE,\n",
        "        num_samples=100,\n",
        "        target_dim=1,\n",
        "        feat_dynamic_real_dim=dataset.num_feat_dynamic_real,\n",
        "        past_feat_dynamic_real_dim=dataset.num_past_feat_dynamic_real,\n",
        "      )\n",
        "      #print(\"MOE used\")\n",
        "    else:\n",
        "      model = MoiraiForecast(\n",
        "        module=MoiraiModule.from_pretrained(MOIRAI_MODEL_STR),\n",
        "        prediction_length=PREDICTION_LENGTH,\n",
        "        context_length=CONTEXT_LENGTH,\n",
        "        patch_size=MOIRAI_PATCH_SIZE,\n",
        "        num_samples=100,\n",
        "        target_dim=1,\n",
        "        feat_dynamic_real_dim=dataset.num_feat_dynamic_real,\n",
        "        past_feat_dynamic_real_dim=dataset.num_past_feat_dynamic_real,\n",
        "      )\n",
        "      #print(\"No MOE used\")\n",
        "\n",
        "    '''\n",
        "\n",
        "    # Step 2.2: Prepare fine-tuned model by loading model weights from ckpt file\n",
        "    checkpoint_path = \"/content/last.ckpt\"\n",
        "\n",
        "    # Load the model\n",
        "    model = MoiraiForecast.load_from_checkpoint(checkpoint_path,\n",
        "    prediction_length=PREDICTION_LENGTH,\n",
        "    context_length=CONTEXT_LENGTH,\n",
        "    patch_size=PATCH_SIZE,\n",
        "    num_samples=100,\n",
        "    target_dim=1,\n",
        "    feat_dynamic_real_dim=dataset.num_feat_dynamic_real,\n",
        "    past_feat_dynamic_real_dim=dataset.num_past_feat_dynamic_real)\n",
        "    '''\n",
        "\n",
        "    # Step 6: Get probabilistic predictions\n",
        "    predictor = model.create_predictor(batch_size=MOIRAI_BATCH_SIZE)\n",
        "    forecasts = list(predictor.predict(test_data.input))\n",
        "\n",
        "    # Step 7: Get point predictions\n",
        "    # Get predictions from forecasts\n",
        "    predictions = forecasts[0].mean_ts\n",
        "    # Feature added here!!!\n",
        "    # Truncate negative predictions to 0\n",
        "    predictions = np.maximum(predictions, 0)\n",
        "\n",
        "    # Get actuals for metric calculations later\n",
        "    actuals = df.loc[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH][\"OT\"]\n",
        "\n",
        "    # Change type\n",
        "    MOIRAI_predictions = predictions.to_numpy()\n",
        "    MOIRAI_actuals = actuals.to_numpy()\n",
        "\n",
        "    # Step 8: Do evaluations\n",
        "    MOIRAI_rmse = np.sqrt(np.mean((MOIRAI_predictions - MOIRAI_actuals)**2))\n",
        "    MOIRAI_mae = mean_absolute_error(MOIRAI_actuals, MOIRAI_predictions)\n",
        "    MOIRAI_r2 = r2_score(MOIRAI_actuals, MOIRAI_predictions)\n",
        "    MOIRAI_smape = calc_smape(MOIRAI_actuals, MOIRAI_predictions)\n",
        "\n",
        "    print(f\"PL={PREDICTION_LENGTH}, CL={CONTEXT_LENGTH}, Model={MOIRAI_MODEL_PATH_SAFE}\")\n",
        "    #print(f\"Length of: RMSE={len(MOIRAI_rmse_list)}, MAE={len(MOIRAI_mae_list)}, SMAPE={len(MOIRAI_smape_list)}, R2={len(MOIRAI_r2_list)}\")\n",
        "    #print(f\"Mean of: RMSE={np.mean(MOIRAI_rmse_list):.4f}, MAE={np.mean(MOIRAI_mae_list):.4f}, SMAPE={np.mean(MOIRAI_smape_list):.2f}%, R^2={np.mean(MOIRAI_r2_list):.4f}\")\n",
        "    #MOIRAI_RMSE_MED = np.median(MOIRAI_rmse_list)\n",
        "    #MOIRAI_MAE_MED = np.median(MOIRAI_mae_list)\n",
        "    #MOIRAI_SMAPE_MED = np.median(MOIRAI_smape_list)\n",
        "    #MOIRAI_R2_MED = np.median(MOIRAI_r2_list)\n",
        "    #print(f\"Median of: RMSE={MOIRAI_RMSE_MED:.4f}, MAE={MOIRAI_MAE_MED:.4f}, SMAPE={MOIRAI_SMAPE_MED:.2f}%, R^2={MOIRAI_R2_MED:.4f}\")\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "    # Prepare for Plot\n",
        "    # Get prediction intervals\n",
        "    MOIRAI_lower_50 = forecasts[0].quantile(0.25)  # 25th percentile (lower bound)\n",
        "    MOIRAI_upper_50 = forecasts[0].quantile(0.75)  # 75th percentile (upper bound)\n",
        "    MOIRAI_lower_90 = forecasts[0].quantile(0.05)  # 5th percentile (lower bound)\n",
        "    MOIRAI_upper_90 = forecasts[0].quantile(0.95)  # 95th percentile (upper bound)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Plot filtered data all togehter\n",
        "    plt.plot(df[BEGINNING_TIMESTAMP:][\"OT\"].iloc[:PREDICTION_LENGTH], color=\"black\", linestyle=\"--\", label=\"True values\")\n",
        "    plt.plot(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH].index, MOIRAI_predictions, color=\"orange\", label=\"MOIRAI Predictions\")\n",
        "    plt.plot(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH].index, DeepAR_predictions, color=\"blue\", label=\"DeepAR Predictions\")\n",
        "    plt.plot(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH].index, LSTM_predictions[(LSTM_PREDICTIONS_INDEX_SHIFTED-1)+START_HOUR], color=\"green\", label=\"LSTM Predictions\")\n",
        "\n",
        "    # Add 50% Prediction Interval (Shaded)\n",
        "    plt.fill_between(\n",
        "        df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH].index,\n",
        "        MOIRAI_lower_50[len(MOIRAI_lower_50)-len(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH]):],\n",
        "        MOIRAI_upper_50[len(MOIRAI_upper_50)-len(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH]):],\n",
        "        color=\"orange\", alpha=0.2, label=\"MOIRAI 50% PI\"\n",
        "    )\n",
        "\n",
        "    # Add 90% Prediction Interval (Shaded)\n",
        "    plt.fill_between(\n",
        "        df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH].index,\n",
        "        MOIRAI_lower_90[len(MOIRAI_lower_90)-len(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH]):],\n",
        "        MOIRAI_upper_90[len(MOIRAI_upper_90)-len(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH]):],\n",
        "        color=\"orange\", alpha=0.075, label=\"MOIRAI 90% PI\"\n",
        "    )\n",
        "    # Add 50% Prediction Interval (Shaded)\n",
        "    plt.fill_between(\n",
        "        df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH].index,\n",
        "        DeepAR_lower_50[len(DeepAR_lower_50)-len(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH]):],\n",
        "        DeepAR_upper_50[len(DeepAR_upper_50)-len(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH]):],\n",
        "        color=\"blue\", alpha=0.2, label=\"DeepAR 50% PI\"\n",
        "    )\n",
        "\n",
        "    # Add 90% Prediction Interval (Shaded)\n",
        "    plt.fill_between(\n",
        "        df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH].index,\n",
        "        DeepAR_lower_90[len(DeepAR_lower_90)-len(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH]):],\n",
        "        DeepAR_upper_90[len(DeepAR_upper_90)-len(df[BEGINNING_TIMESTAMP:].iloc[:PREDICTION_LENGTH]):],\n",
        "        color=\"blue\", alpha=0.075, label=\"DeepAR 90% PI\"\n",
        "    )\n",
        "\n",
        "    plt.legend(loc=\"upper right\", fontsize=\"small\")\n",
        "    plt.ylabel(\"Oil Temperature\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.title(f\"LSTM, DeepAR & MOIRAI Base Forecast (starts {BEGINNING_TIMESTAMP})\")\n",
        "    plt.figtext(0.1, 0.9000, f\"MOIRAI: RMSE={MOIRAI_rmse:.4f}, MAE={MOIRAI_mae:.4f}, SMAPE={MOIRAI_smape:.2f}%, R^2={MOIRAI_r2:.4f}\", fontsize=6, color='black')\n",
        "    plt.figtext(0.1, 0.8700, f\"DeepAR: RMSE={DeepAR_rmse:.4f}, MAE={DeepAR_mae:.4f}, SMAPE={DeepAR_smape:.2f}%, R^2={DeepAR_r2:.4f}\", fontsize=6, color='black')\n",
        "    plt.figtext(0.1, 0.8400, f\"LSTM: RMSE={LSTM_rmse:.4f}, MAE={LSTM_mae:.4f}, SMAPE={LSTM_smape:.2f}%, R^2={LSTM_r2:.4f}\", fontsize=6, color='black')\n",
        "    plt.figtext(0.1, 0.8100,f\"LSTM&DeepAR&MOIRAI_Features={dataset.feat_dynamic_real}\", fontsize=4, color='black')\n",
        "    plt.figtext(0.1, 0.7800,f\"DeepAR&MOIRAI_Past_Features={dataset.past_feat_dynamic_real}\", fontsize=4, color='black')\n",
        "    plt.figtext(0.1, 0.7500,f\"LSTM: HIDDEN_SIZE={LSTM_HIDDEN_SIZE}, BATCH={LSTM_BATCH_SIZE}, LR={LSTM_LR}, Epochs={LSTM_NUM_EPOCHS}\", fontsize=4, color='black')\n",
        "    plt.figtext(0.1, 0.7200,f\"MOIRAI: PATCH={MOIRAI_PATCH_SIZE}, BATCH={MOIRAI_BATCH_SIZE}, LR=n.A., Epochs=n.A.\", fontsize=4, color='black')\n",
        "    plt.figtext(0.1, 0.6900,f\"DeepAR: HIDDEN_SIZE={DeepAR_HIDDEN_SIZE}, RNN_LAYERS={DeepAR_NUM_LAYERS}, LR={DeepAR_LR}, Epochs={DeepAR_NUM_EPOCHS}\", fontsize=4, color='black')\n",
        "    plt.figtext(0.1, 0.6600,f\"Dataset={file_name_no_extension(FILEPATH)}\", fontsize=4, color='black')\n",
        "    plt.figtext(0.1, 0.6300,f\"Pre_L={PREDICTION_LENGTH}, Con_L={CONTEXT_LENGTH}\", fontsize=6, color='black')\n",
        "\n",
        "    # Set y-axis limits\n",
        "    plt.ylim(12.0, 30.0)\n",
        "\n",
        "    # Set y-axis limits and x-axis formatting\n",
        "    ax = plt.gca()\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
        "    ax.xaxis.set_major_locator(mdates.DayLocator())\n",
        "    plt.xticks(rotation=25)\n",
        "\n",
        "    # Adjust layout and save plot\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"PL={PREDICTION_LENGTH}-CL={CONTEXT_LENGTH}-{BEGINNING_TIMESTAMP}-LSTM_DeepAR_MOIRAIBase_Forecasts.pdf\")\n",
        "    #plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    # Reset plot before next round\n",
        "    plt.figure().clear()\n",
        "    plt.close()\n",
        "    plt.cla()\n",
        "    plt.clf()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5WvOywrXWbW"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Step5.2: Prepare fine-tuned model by loading model weights from ckpt file\n",
        "checkpoint_path = \"/content/multirun/2025-02-11/15-40-14/0/checkpoints/epoch=13-step=1400.ckpt\"\n",
        "\n",
        "# Load the model\n",
        "model = MoiraiForecast.load_from_checkpoint(checkpoint_path,\n",
        "      prediction_length=PREDICTION_LENGTH,\n",
        "      context_length=CONTEXT_LENGTH,\n",
        "      patch_size=PATCH_SIZE,\n",
        "      num_samples=100,\n",
        "      target_dim=1,\n",
        "      feat_dynamic_real_dim=dataset.num_feat_dynamic_real,\n",
        "      past_feat_dynamic_real_dim=dataset.num_past_feat_dynamic_real)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN6y68zkhZS2"
      },
      "outputs": [],
      "source": [
        "# Fine-tuning in regards to https://github.com/SalesforceAIResearch/uni2ts/blob/main/README.md#fine-tuning\n",
        "# Step 1 Set Data Path Directory\n",
        "!echo \"CUSTOM_DATA_PATH=/content/uni2ts/\" >> .env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es3PtupPF-OB"
      },
      "outputs": [],
      "source": [
        "!echo \"PYTHONPATH=/content/uni2ts\" >> .env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9NAOCxbYZwC",
        "outputId": "d60a0ab3-f3cd-41e4-873d-ec18a6e01367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUSTOM_DATA_PATH=/content/uni2ts/\n",
            "PYTHONPATH=/content/uni2ts\n"
          ]
        }
      ],
      "source": [
        "!cat .env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogaNfoMChlvJ",
        "outputId": "a4ae6c56-0db1-4c82-e8b5-2e04a9bbb5de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inferred frequency: H. Using this value for the 'freq' parameter.\n",
            "Generating train split: 1 examples [00:00,  4.58 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 1/1 [00:00<00:00, 263.00 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 2.1 process dataset\n",
        "!python -m uni2ts.data.builder.simple customdataset /content/uni2ts/230401_250108_PT1H_Solcast_reduced_features.csv --dataset_type wide_multivariate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsF2EKXEktSI",
        "outputId": "048f19bc-a972-42e2-f7df-72612a5907b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     dc_power  air_temp  azimuth  cloud_opacity  dhi  dni  ghi  zenith\n",
            "date                                                                                  \n",
            "2023-04-01 01:00:00       0.0         8      -27           37.4    0    0    0     125\n",
            "2023-04-01 02:00:00       0.0         8      -43           46.6    0    0    0     120\n",
            "2023-04-01 03:00:00       0.0         8      -57           40.6    0    0    0     112\n",
            "2023-04-01 04:00:00       0.0         7      -70           47.6    0    0    0     103\n",
            "2023-04-01 05:00:00       0.0         7      -81           58.2    0    0    0      93\n",
            "...                       ...       ...      ...            ...  ...  ...  ...     ...\n",
            "2024-08-31 03:00:00       0.0        19      -55            0.0    0    0    0     107\n",
            "2024-08-31 04:00:00       0.0        19      -67           16.5    0    0    0      98\n",
            "2024-08-31 05:00:00       0.0        19      -79           39.8    7    0    7      88\n",
            "2024-08-31 06:00:00       0.0        19      -90           23.9   94   47  104      78\n",
            "2024-08-31 07:00:00       0.1        21     -101            0.0   89  575  303      68\n",
            "\n",
            "[12439 rows x 8 columns]\n",
            "Inferred frequency: H. Using this value for the 'freq' parameter.\n",
            "Generating train split: 8 examples [00:00, 49.89 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 8/8 [00:00<00:00, 2004.21 examples/s]\n",
            "                     dc_power  air_temp  azimuth  cloud_opacity  dhi  dni  ghi  zenith\n",
            "date                                                                                  \n",
            "2023-04-01 01:00:00       0.0         8      -27           37.4    0    0    0     125\n",
            "2023-04-01 02:00:00       0.0         8      -43           46.6    0    0    0     120\n",
            "2023-04-01 03:00:00       0.0         8      -57           40.6    0    0    0     112\n",
            "2023-04-01 04:00:00       0.0         7      -70           47.6    0    0    0     103\n",
            "2023-04-01 05:00:00       0.0         7      -81           58.2    0    0    0      93\n",
            "...                       ...       ...      ...            ...  ...  ...  ...     ...\n",
            "2025-01-07 20:00:00       0.0         1       79           32.1    0    0    0     131\n",
            "2025-01-07 21:00:00       0.0         1       65           73.2    0    0    0     140\n",
            "2025-01-07 22:00:00       0.0         2       45           33.5    0    0    0     149\n",
            "2025-01-07 23:00:00       0.0         1       18           40.6    0    0    0     154\n",
            "2025-01-08 00:00:00       0.0         2      -14           51.0    0    0    0     155\n",
            "\n",
            "[15552 rows x 8 columns]\n",
            "Inferred frequency: H. Using this value for the 'freq' parameter.\n",
            "Generating train split: 8 examples [00:00, 52.27 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 8/8 [00:00<00:00, 2196.11 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 2.2 Set offset\n",
        "!python -m uni2ts.data.builder.simple customdataset /content/uni2ts/230401_250108_PT1H_Solcast_reduced_features.csv --date_offset '2024-08-31 07:00:00'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "903wnpN-PDG2"
      },
      "outputs": [],
      "source": [
        "#!mv content/uni2ts/cli content/uni2ts/src/uni2ts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqmjyQbeCqjU"
      },
      "outputs": [],
      "source": [
        "# Step 3 (move cli dir to src/uni2ts first!!!!)\n",
        "# Set Batch size here /content/uni2ts/src/uni2ts/cli/conf/finetune/default.yaml to lower value\n",
        "# For moirai large with A100 40GB RAM use 16 as batch size in val_dataloader and train_dataloader section\n",
        "\n",
        "#!python -m uni2ts.cli.train -cp conf/finetune run_name=example_run model=moirai_1.1_R_large data=etth1 val_data=etth1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z-quJtw5FZL",
        "outputId": "32c2b9eb-5eda-409b-b738-0c7dfc50fa08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-02-11 15:40:14,959][HYDRA] Launching 1 jobs locally\n",
            "[2025-02-11 15:40:14,959][HYDRA] \t#0 : run_name=example_run model=moirai_1.1_R_base data=customdataset val_data=customdataset model.module_kwargs.dropout_p=0.2 trainer.max_epochs=25 model.lr=1e-07 train_dataloader.batch_size=24 val_dataloader.batch_size=24\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "[2025-02-11 15:40:16,903][datasets][INFO] - PyTorch version 2.4.1 available.\n",
            "[2025-02-11 15:40:16,903][datasets][INFO] - TensorFlow version 2.18.0 available.\n",
            "[2025-02-11 15:40:16,904][datasets][INFO] - JAX version 0.4.33 available.\n",
            "Seed set to 0\n",
            "2025-02-11 15:40:17.397359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739288417.422296   43645 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739288417.429823   43645 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name   | Type         | Params | Mode \n",
            "------------------------------------------------\n",
            "0 | module | MoiraiModule | 91.4 M | train\n",
            "------------------------------------------------\n",
            "91.4 M    Trainable params\n",
            "0         Non-trainable params\n",
            "91.4 M    Total params\n",
            "365.431   Total estimated model params size (MB)\n",
            "253       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.360, train/PackedNLLLoss=3.230]Metric val/PackedNLLLoss improved. New best score: 2.360\n",
            "Epoch 1: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0, val/PackedNLLLoss=2.360, train/PackedNLLLoss=3.230]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.300, train/PackedNLLLoss=3.120]Metric val/PackedNLLLoss improved by 0.059 >= min_delta = 0.0. New best score: 2.302\n",
            "Epoch 2: |          | 100/? [02:12<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.300, train/PackedNLLLoss=3.120]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.270, train/PackedNLLLoss=3.050]Metric val/PackedNLLLoss improved by 0.033 >= min_delta = 0.0. New best score: 2.268\n",
            "Epoch 3: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0, val/PackedNLLLoss=2.270, train/PackedNLLLoss=3.050]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.250, train/PackedNLLLoss=3.000]Metric val/PackedNLLLoss improved by 0.022 >= min_delta = 0.0. New best score: 2.247\n",
            "Epoch 4: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0, val/PackedNLLLoss=2.250, train/PackedNLLLoss=3.000]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.220, train/PackedNLLLoss=2.980]Metric val/PackedNLLLoss improved by 0.022 >= min_delta = 0.0. New best score: 2.225\n",
            "Epoch 5: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0, val/PackedNLLLoss=2.220, train/PackedNLLLoss=2.980]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.210, train/PackedNLLLoss=2.950]Metric val/PackedNLLLoss improved by 0.012 >= min_delta = 0.0. New best score: 2.213\n",
            "Epoch 6: |          | 100/? [02:12<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.210, train/PackedNLLLoss=2.950]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.200, train/PackedNLLLoss=2.930]Metric val/PackedNLLLoss improved by 0.014 >= min_delta = 0.0. New best score: 2.199\n",
            "Epoch 7: |          | 100/? [02:12<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.200, train/PackedNLLLoss=2.930]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.190, train/PackedNLLLoss=2.900]Metric val/PackedNLLLoss improved by 0.013 >= min_delta = 0.0. New best score: 2.186\n",
            "Epoch 8: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0, val/PackedNLLLoss=2.190, train/PackedNLLLoss=2.900]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.170, train/PackedNLLLoss=2.890]Metric val/PackedNLLLoss improved by 0.012 >= min_delta = 0.0. New best score: 2.174\n",
            "Epoch 9: |          | 100/? [02:12<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.170, train/PackedNLLLoss=2.890]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.170, train/PackedNLLLoss=2.870]Metric val/PackedNLLLoss improved by 0.006 >= min_delta = 0.0. New best score: 2.167\n",
            "Epoch 10: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0, val/PackedNLLLoss=2.170, train/PackedNLLLoss=2.870]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.160, train/PackedNLLLoss=2.860]Metric val/PackedNLLLoss improved by 0.004 >= min_delta = 0.0. New best score: 2.163\n",
            "Epoch 11: |          | 100/? [02:12<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.160, train/PackedNLLLoss=2.860]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.160, train/PackedNLLLoss=2.850]Metric val/PackedNLLLoss improved by 0.008 >= min_delta = 0.0. New best score: 2.156\n",
            "Epoch 12: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0, val/PackedNLLLoss=2.160, train/PackedNLLLoss=2.850]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.150, train/PackedNLLLoss=2.850]Metric val/PackedNLLLoss improved by 0.004 >= min_delta = 0.0. New best score: 2.152\n",
            "Epoch 13: |          | 100/? [02:12<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.150, train/PackedNLLLoss=2.850]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.150, train/PackedNLLLoss=2.840]Metric val/PackedNLLLoss improved by 0.004 >= min_delta = 0.0. New best score: 2.148\n",
            "Epoch 14: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0, val/PackedNLLLoss=2.150, train/PackedNLLLoss=2.840]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15: |          | 100/? [02:12<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.150, train/PackedNLLLoss=2.830]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16: |          | 100/? [02:12<00:00,  0.76it/s, v_num=0, val/PackedNLLLoss=2.150, train/PackedNLLLoss=2.830]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.150, train/PackedNLLLoss=2.820]Monitored metric val/PackedNLLLoss did not improve in the last 3 records. Best score: 2.148. Signaling Trainer to stop.\n",
            "Epoch 16: |          | 100/? [02:13<00:00,  0.75it/s, v_num=0, val/PackedNLLLoss=2.150, train/PackedNLLLoss=2.820]\n",
            "/usr/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 22 leaked semaphore objects to clean up at shutdown\n",
            "  warnings.warn('resource_tracker: There appear to be %d '\n"
          ]
        }
      ],
      "source": [
        "# Use Hydra's Sweeping Feature for Hyperparameter Search\n",
        "!python -m uni2ts.cli.train --multirun -cp conf/finetune run_name=example_run model=moirai_1.1_R_base data=customdataset val_data=customdataset \\\n",
        "  model.module_kwargs.dropout_p=0.2 \\\n",
        "  trainer.max_epochs=25 \\\n",
        "  model.lr=1e-7 \\\n",
        "  train_dataloader.batch_size=24 \\\n",
        "  val_dataloader.batch_size=24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMAEx64Har1x"
      },
      "outputs": [],
      "source": [
        "# Show Tensorboard with results\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir /content/multirun\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ppn9_O3-WJJ0"
      },
      "outputs": [],
      "source": [
        "#Export outputs\n",
        "#!zip -r outputs.zip /content/outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_B_t-0YOvLq"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "#!python -m uni2ts.cli.eval run_name=example_eval_1 model=moirai_1.0_R_small model.patch_size=32 model.context_length=1000 data=etth1_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwrqN3dk8vB2"
      },
      "outputs": [],
      "source": [
        "#import gc\n",
        "\n",
        "# Invoke garbage collector\n",
        "#gc.collect()\n",
        "\n",
        "# Clear GPU cache\n",
        "#torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc0d86a8aca74b6aa143ef4f08f6cdc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f03cff7868524d5383021b2031243c52",
              "IPY_MODEL_a81dc12a61994d81b4e0f49b2ac7a425",
              "IPY_MODEL_f21a7b516e1e43d79f9d9bf0014cd1aa"
            ],
            "layout": "IPY_MODEL_32a5388b987a4713b3dc6ee4cc91b9ad"
          }
        },
        "f03cff7868524d5383021b2031243c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b32e5259b2e43b2afdce4f57faeffdd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_330de12a817b4bacb57b751c9cbc7b7b",
            "value": "Epoch‚Äá24:‚Äá"
          }
        },
        "a81dc12a61994d81b4e0f49b2ac7a425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_831885f9a5614c1e83b001bd194b2b68",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b822939194948edb9e567b95de10955",
            "value": 1
          }
        },
        "f21a7b516e1e43d79f9d9bf0014cd1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c148f95e16848628873e503d4338811",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e61e0b91577e46a8921e51d3d0ecb192",
            "value": "‚Äá50/?‚Äá[00:13&lt;00:00,‚Äá‚Äá3.64it/s,‚Äáv_num=0,‚Äátrain_loss=1.510]"
          }
        },
        "32a5388b987a4713b3dc6ee4cc91b9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "7b32e5259b2e43b2afdce4f57faeffdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "330de12a817b4bacb57b751c9cbc7b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "831885f9a5614c1e83b001bd194b2b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b822939194948edb9e567b95de10955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c148f95e16848628873e503d4338811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e61e0b91577e46a8921e51d3d0ecb192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a96f2301dcc4666b18271114cc34efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ac267a0bdc44b31b787a7e1ac47ed02",
              "IPY_MODEL_94aa5ce6d2ba43f59495e45383b027c6",
              "IPY_MODEL_eddfc6d5b57544bbb7b5a4c9a1b56858"
            ],
            "layout": "IPY_MODEL_241485d020c54097a4de2ec33fd1e34e"
          }
        },
        "9ac267a0bdc44b31b787a7e1ac47ed02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10918e541f4b4a68833c1bda7cb9166e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fa830d1c600043f9a2178f6028c4d1b8",
            "value": "config.json:‚Äá100%"
          }
        },
        "94aa5ce6d2ba43f59495e45383b027c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9307391a3e19437c82876920377e7021",
            "max": 683,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_548b21f922d34afbb1ee3793cc7774b1",
            "value": 683
          }
        },
        "eddfc6d5b57544bbb7b5a4c9a1b56858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc7804ce417d4e33952a038c46350ce7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_15b970e6b4fe4004908f4db9c2566ca8",
            "value": "‚Äá683/683‚Äá[00:00&lt;00:00,‚Äá56.9kB/s]"
          }
        },
        "241485d020c54097a4de2ec33fd1e34e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10918e541f4b4a68833c1bda7cb9166e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa830d1c600043f9a2178f6028c4d1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9307391a3e19437c82876920377e7021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548b21f922d34afbb1ee3793cc7774b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc7804ce417d4e33952a038c46350ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15b970e6b4fe4004908f4db9c2566ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43793583ff414f9884263bb7a218c475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41669828f3334e26975cb35321d01f51",
              "IPY_MODEL_c4db20f3cffa4dfca8c5d8eb36999d41",
              "IPY_MODEL_794a35f1460d4d50b2627d164e192fd1"
            ],
            "layout": "IPY_MODEL_1d9778648d644caaa3273745ad15b521"
          }
        },
        "41669828f3334e26975cb35321d01f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_825d7ba13c544260a9c0e25ad4cb23e7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8abf5d19f02941c2a82025193f91b13b",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "c4db20f3cffa4dfca8c5d8eb36999d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee95827ec844b5da11c189ad203dc70",
            "max": 365449072,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ff17b2403a84ebcb2548bc108db7a53",
            "value": 365449072
          }
        },
        "794a35f1460d4d50b2627d164e192fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92519c046224b51bb8d4668b9e25d8d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_41c102a4865547d5abcd39b5a84643b4",
            "value": "‚Äá365M/365M‚Äá[00:03&lt;00:00,‚Äá106MB/s]"
          }
        },
        "1d9778648d644caaa3273745ad15b521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "825d7ba13c544260a9c0e25ad4cb23e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8abf5d19f02941c2a82025193f91b13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aee95827ec844b5da11c189ad203dc70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff17b2403a84ebcb2548bc108db7a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e92519c046224b51bb8d4668b9e25d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c102a4865547d5abcd39b5a84643b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0904154404e453fa1ec5dd3d74e949d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4c79a5d3c3d4b9487e1b05c0ac6a7a0",
              "IPY_MODEL_dc2bc0558b2c405ab2769d1ef28baebf",
              "IPY_MODEL_ac6fccc2caf8484c8c48ede352823013"
            ],
            "layout": "IPY_MODEL_2ec9b5634b484e97bbe43ef208973be1"
          }
        },
        "a4c79a5d3c3d4b9487e1b05c0ac6a7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d47ef833ad74215b6e896833059fab1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_366d129e2c9e4152881c89cd19dd992e",
            "value": "Epoch‚Äá24:‚Äá"
          }
        },
        "dc2bc0558b2c405ab2769d1ef28baebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb6f6ce7f47f455b85570abaaae0d82c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dce88247da8d45ff9afd233bf9cbf0f5",
            "value": 1
          }
        },
        "ac6fccc2caf8484c8c48ede352823013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a39dae672594e8fad0190e527b04dc6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_905e293786f140d6b1afd6994b9f9dde",
            "value": "‚Äá50/?‚Äá[00:14&lt;00:00,‚Äá‚Äá3.40it/s,‚Äáv_num=1,‚Äátrain_loss=1.460]"
          }
        },
        "2ec9b5634b484e97bbe43ef208973be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5d47ef833ad74215b6e896833059fab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366d129e2c9e4152881c89cd19dd992e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb6f6ce7f47f455b85570abaaae0d82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce88247da8d45ff9afd233bf9cbf0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a39dae672594e8fad0190e527b04dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "905e293786f140d6b1afd6994b9f9dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "053cc02e3de3434790d020ec024a912f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5201de53a1c944c6862d7b2dc3027584",
              "IPY_MODEL_6b9b5e4699784f7b8a0833c8677e1a2b",
              "IPY_MODEL_cd5c2600f4464ddcb4675cf35abf56e8"
            ],
            "layout": "IPY_MODEL_5e1936fcb4204b5cac8f67d22622ada6"
          }
        },
        "5201de53a1c944c6862d7b2dc3027584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c36c0a577424904b607192b7d76dfa2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_66a3b53135db4db2afdd0b36dae51541",
            "value": "Epoch‚Äá24:‚Äá"
          }
        },
        "6b9b5e4699784f7b8a0833c8677e1a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89e00378bcd64d6392893929501817d8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bd617cae5904119b783c462fb7aa3be",
            "value": 1
          }
        },
        "cd5c2600f4464ddcb4675cf35abf56e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fdaad6c5c3f4600a3b70e8695149746",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c038d45d53be47bba66e41caa1c83416",
            "value": "‚Äá50/?‚Äá[00:15&lt;00:00,‚Äá‚Äá3.22it/s,‚Äáv_num=2,‚Äátrain_loss=1.420]"
          }
        },
        "5e1936fcb4204b5cac8f67d22622ada6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8c36c0a577424904b607192b7d76dfa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a3b53135db4db2afdd0b36dae51541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89e00378bcd64d6392893929501817d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd617cae5904119b783c462fb7aa3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fdaad6c5c3f4600a3b70e8695149746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c038d45d53be47bba66e41caa1c83416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}